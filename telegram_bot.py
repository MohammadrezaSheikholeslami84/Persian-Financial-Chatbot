# telegram_financial_bot.py
import logging
import os
from dotenv import load_dotenv
import whisper
from pydub import AudioSegment
from telegram import ReplyKeyboardMarkup, KeyboardButton, Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

import financial_core  # your financial logic


# --- Load environment variables ---
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

# --- Logging ---
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- Load Whisper model ---
MODEL_SIZE = "large"  # "tiny", "base", "small", "medium", "large"
print(f"Loading Whisper model '{MODEL_SIZE}'...")
model = whisper.load_model(MODEL_SIZE)
print("Whisper model loaded")


# --- Keyboard ---
main_keyboard = ReplyKeyboardMarkup(
    [
        [KeyboardButton("ğŸ’µ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±"), KeyboardButton("ğŸª™ Ù‚ÛŒÙ…Øª Ø·Ù„Ø§")],
        [KeyboardButton("ğŸ“ˆ Ø¨ÙˆØ±Ø³"), KeyboardButton("ğŸ“Š Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„")],
        [KeyboardButton("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§")],
    ],
    resize_keyboard=True,
)


# --- Helper function ---
def get_custom_response(text: str) -> dict:
    """Send text to financial module and return response."""
    try:
        return financial_core.process_request(text)
    except Exception as e:
        logger.error(f"Error processing request: {e}")
        return {"type": "text", "text": "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª."}


# --- Handlers ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    await update.message.reply_html(
        rf"Ø³Ù„Ø§Ù… {user.mention_html()}! ğŸ‘‹\nÙ…Ù† Ø¯Ø³ØªÛŒØ§Ø± Ù…Ø§Ù„ÛŒ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…. Ù…ØªÙ† ÛŒØ§ ÙˆÛŒØ³ Ø¨ÙØ±Ø³ØªÛŒØ¯.",
        reply_markup=main_keyboard
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    help_text = (
        "ğŸ“Œ <b>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§Øª:</b>\n"
        "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÛŒÚ©ÛŒ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…ØªÙ† Ø¨ÙØ±Ø³ØªÛŒØ¯:\n"
        "ğŸ’µ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±\nğŸª™ Ù‚ÛŒÙ…Øª Ø·Ù„Ø§\nğŸ“ˆ Ø¨ÙˆØ±Ø³\nğŸ“Š Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„\n\n"
        "Ù…Ø«Ù„Ø§Ù‹ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯: <code>Ù‚ÛŒÙ…Øª ÛŒÙˆØ±Ùˆ</code>"
    )
    await update.message.reply_html(help_text, reply_markup=main_keyboard)


async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Transcribe Persian voice messages and respond."""
    user_message = update.message
    await user_message.reply_text("Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ØŒ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

    try:
        # Download voice file (.oga)
        voice_file = await user_message.voice.get_file()
        oga_path = f"{voice_file.file_id}.oga"
        await voice_file.download_to_drive(oga_path)

        # Convert .oga to .wav
        wav_path = f"{voice_file.file_id}.wav"
        audio = AudioSegment.from_file(oga_path, format="ogg")
        audio.export(wav_path, format="wav")

        financial_prompt = (
            "Ú¯Ø²Ø§Ø±Ø´ Ø§Ù…Ø±ÙˆØ² Ø¨ÙˆØ±Ø³ Ùˆ Ù‚ÛŒÙ…Øª Ø§Ø±Ø². Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±ØŒ ÛŒÙˆØ±ÙˆØŒ Ø¯Ø±Ù‡Ù… Ùˆ Ù¾ÙˆÙ†Ø¯ Ú†Ù†Ø¯ Ø§Ø³ØªØŸ "
            "ÙˆØ¶Ø¹ÛŒØª Ø·Ù„Ø§ØŒ Ø³Ú©Ù‡ Ø§Ù…Ø§Ù…ÛŒØŒ Ø³Ú©Ù‡ Ø¨Ù‡Ø§Ø± Ø¢Ø²Ø§Ø¯ÛŒØŒ Ø±Ø¨Ø¹ Ø³Ú©Ù‡ Ùˆ Ù†ÛŒÙ… Ø³Ú©Ù‡ Ø¯Ø± Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡ Ú†Ø·ÙˆØ± Ø¨ÙˆØ¯ØŸ "
            "Ù„Ø·ÙØ§Ù‹ ÙˆØ¶Ø¹ÛŒØª Ø´Ø§Ø®Øµ Ú©Ù„ØŒ Ø´Ø§Ø®Øµ Ù‡Ù… ÙˆØ²Ù† Ùˆ Ø´Ø§Ø®Øµ ÙØ±Ø§Ø¨ÙˆØ±Ø³ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯. "
            "ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø´Ø³ØªØ§ØŒ Ø®ÙˆØ¯Ø±ÙˆØŒ Ø®Ø³Ø§Ù¾Ø§ØŒ ÙÙˆÙ„Ø§Ø¯ØŒ Ø´Ù¾Ù†Ø§ØŒ ÙˆØ¨Ù…Ù„ØªØŒ ÙˆØªØ¬Ø§Ø±Øª Ùˆ ÙˆØºØ¯ÛŒØ±. "
            "Ø§Ø®Ø¨Ø§Ø± Ø³Ù‡Ø§Ù… Ø§Ù¾Ù„ØŒ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØªØŒ Ùˆ ØªØ³Ù„Ø§. "
            "Ù‚ÛŒÙ…Øª Ø¨ÛŒØª Ú©ÙˆÛŒÙ†ØŒ Ø§ØªØ±ÛŒÙˆÙ… Ùˆ ØªØªØ± Ø¯Ø± Ø¨ÛŒØ³Øª Ùˆ Ú†Ù‡Ø§Ø± Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡. "
            "Ø¢ÛŒØ§ Ø¯ÛŒØ±ÙˆØ² Ø¯Ù‡ Ø¯Ø±ØµØ¯ ÛŒØ§ Ù¾Ù†Ø¬Ø§Ù‡ Ø¯Ø±ØµØ¯ Ø±Ø´Ø¯ ÛŒØ§ Ø§ÙØª Ø¯Ø§Ø´ØªÛŒÙ…ØŸ"
            "Ú¯Ø²Ø§Ø±Ø´ Ø§Ù…Ø±ÙˆØ² Ø¨ÙˆØ±Ø³ Ùˆ Ù‚ÛŒÙ…Øª Ø§Ø±Ø². Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±ØŒ ÛŒÙˆØ±Ùˆ Ùˆ Ø³Ú©Ù‡ Ø¨Ù‡Ø§Ø± Ø¢Ø²Ø§Ø¯ÛŒ Ø§Ù…Ø±ÙˆØ² Ú†Ù†Ø¯ Ø§Ø³ØªØŸ "
            "Ù„Ø·ÙØ§Ù‹ Ù†Ù…ÙˆØ¯Ø§Ø± Ø´Ø§Ø®Øµ Ú©Ù„ Ø±Ø§ Ø¯Ø± Ù¾Ù†Ø¬ Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡ØŒ Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡ Ùˆ Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒÙ… Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡. "
            "Ù„Ø·ÙØ§Ù‹ Ú†Ø§Ø±Øª Ø´Ø§Ø®Øµ Ú©Ù„ Ø±Ø§ Ø¯Ø± Ù¾Ù†Ø¬ Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡ØŒ Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡ Ùˆ Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡ Ùˆ Ø³Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒÙ… Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡. "
            "ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø´Ø³ØªØ§ Ùˆ Ø®ÙˆØ¯Ø±Ùˆ. "
            "Ø§Ø®Ø¨Ø§Ø± Ø³Ù‡Ø§Ù… Ø§Ù¾Ù„ Ùˆ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª. "
            "Ù‚ÛŒÙ…Øª Ø¨ÛŒØª Ú©ÙˆÛŒÙ† Ùˆ Ø§ØªØ±ÛŒÙˆÙ… Ø¯Ø± Ø¨ÛŒØ³Øª Ùˆ Ú†Ù‡Ø§Ø± Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ú†Ø·ÙˆØ± Ø¨ÙˆØ¯ØŸ"
        )
        
        # Transcribe with Whisper
        result = model.transcribe(wav_path, language="fa", fp16=False,initial_prompt=financial_prompt)
        transcribed_text = result["text"]
        logger.info(f"Transcribed text: {transcribed_text}")

        # Get financial response
        response = get_custom_response(transcribed_text)

        if response["type"] == "text":
            await update.message.reply_text(response["text"], reply_markup=main_keyboard)
        elif response["type"] == "image":
            await update.message.reply_photo(
                photo=response["image"],
                caption=response.get("caption", ""),
                reply_markup=main_keyboard
            )
        else:
            await update.message.reply_text("âŒ Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")

    except Exception as e:
        logger.error(f"Voice processing error: {e}")
        await user_message.reply_text("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ.")

    finally:
        # Cleanup
        if os.path.exists(oga_path):
            os.remove(oga_path)
        if os.path.exists(wav_path):
            os.remove(wav_path)


async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle text messages."""
    user_message = update.message.text.strip()
    logger.info(f"User {update.effective_user.id} sent: {user_message}")

    if user_message in ["Ø±Ø§Ù‡Ù†Ù…Ø§", "help", "/help", "â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§"]:
        await help_command(update, context)
        return

    response = get_custom_response(user_message)

    if response["type"] == "text":
        await update.message.reply_text(response["text"], reply_markup=main_keyboard)
    elif response["type"] == "image":
        await update.message.reply_photo(
            photo=response["image"],
            caption=response.get("caption", ""),
            reply_markup=main_keyboard
        )
    else:
        await update.message.reply_text("âŒ Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")


async def exit_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text("Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø®Ø§Ù…ÙˆØ´ Ø´Ø¯Ù† Ø§Ø³Øª. ğŸ‘‹")
    context.application.stop()


# --- Main ---
def main():
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # Handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("exit", exit_command))
    application.add_handler(MessageHandler(filters.VOICE, handle_voice_message))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))

    print("ğŸ¤– Bot is running...")
    application.run_polling()


if __name__ == "__main__":
    main()
