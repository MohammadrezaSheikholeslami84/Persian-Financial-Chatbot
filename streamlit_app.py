import streamlit as st
import time
from io import BytesIO
from financial_core import process_request
from gmini import rag_response
import draw_chart  # handle_chart_request
import pandas as pd

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†
import whisper
from pydub import AudioSegment
import io

# -------------------------------
# Ù„ÙˆØ¯ Ù…Ø¯Ù„ Whisper Ø¨Ø§ cache
# -------------------------------
@st.cache_resource
def load_whisper_model():
    # Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ "medium" ÛŒØ§ "small" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒ ØªØ§ Ø±ÙˆÛŒ Cloud Ø±Ø§Ø­Øªâ€ŒØªØ± Ú©Ø§Ø± Ú©Ù†Ù‡
    return whisper.load_model("medium")

model = load_whisper_model()


class App:
    def __init__(self):
        st.set_page_config(
            page_title="Ú†Øªâ€ŒØ¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù„ÛŒ",
            page_icon="ğŸ’¬",
            layout="centered"
        )
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = [
                {"role": "assistant", "type": "text", "content": "Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‚ÛŒÙ…Øª Ø§Ù†ÙˆØ§Ø¹ Ø¨Ø§Ø²Ø§Ø± Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯!"}
            ]

    def apply_rtl_styles(self):
        st.markdown(""" <style> /* Ø§Ø¹Ù…Ø§Ù„ ÙÙˆÙ†Øª Inter Ø±ÙˆÛŒ Ú©Ù„ Ø§Ù¾ */ html, body, [class*="css"] { font-family: 'Inter', sans-serif; } /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ùˆ ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙ† */ div[data-testid="stChatMessage"] { direction: rtl; text-align: right; } div[data-testid="stChatInput"] textarea { direction: rtl; text-align: right; } h1[data-testid="stTitle"] { text-align: right; direction: rtl; } </style> """, unsafe_allow_html=True)

    def response_generator(self, user_input: str):
        bot_response_data = process_request(user_input)
        full_response = rag_response(user_input, bot_response_data.get("text", ""))
        for word in full_response.split():
            yield word + " "
            time.sleep(0.05)

    def clear_chat_history(self):
        st.session_state.chat_history = [
            {"role": "assistant", "type": "text", "content": "Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‚ÛŒÙ…Øª Ø§Ù†ÙˆØ§Ø¹ Ø¨Ø§Ø²Ø§Ø± Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯!"}
        ]

    # -------------------------------
    # ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Whisper
    # -------------------------------
    def transcribe_audio(self, audio_file):
        audio = AudioSegment.from_file(audio_file)
        audio = audio.set_channels(1).set_frame_rate(16000)
        wav_io = io.BytesIO()
        audio.export(wav_io, format="wav")
        wav_io.seek(0)

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†
        result = model.transcribe(wav_io)
        return result["text"]

    def run(self):
        self.apply_rtl_styles()

        with st.sidebar:
            if st.button("Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú¯ÙØªÚ¯Ùˆ"):
                self.clear_chat_history()
                st.rerun()

        st.title("Ú†Øªâ€ŒØ¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù„ÛŒ ğŸ’¬")

        # Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        for message in st.session_state.chat_history:
            role = message["role"]
            msg_type = message.get("type", "text")

            if msg_type == "image":
                with st.chat_message(role):
                    st.image(message["image"], caption=message.get("caption", ""), use_container_width=True)
            else:
                with st.chat_message(role):
                    st.markdown(message["content"])

        # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
        uploaded_audio = st.file_uploader("ÛŒØ§ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type=["mp3","wav","m4a"])
        if uploaded_audio:
            st.info("Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†...")
            user_input = self.transcribe_audio(uploaded_audio)
            st.success("ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
            st.text_area("Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² ØµÙˆØª:", user_input, height=150)
        else:
            # ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙ†ÛŒ
            user_input = st.chat_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯")

        if user_input:
            st.session_state.chat_history.append({"role": "user", "type": "text", "content": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)

            # Ù¾Ø§Ø³Ø® Ø¯Ø³ØªÛŒØ§Ø±
            features = process_request(user_input)
            response_type = features.get("type")

            if response_type == "image":
                chart_buffer = features.get("image")
                caption = features.get("caption", "Ù†Ù…ÙˆØ¯Ø§Ø±")
                response = {"role": "assistant", "type": "image", "image": chart_buffer, "caption": caption}
                with st.chat_message("assistant"):
                    st.image(response["image"], caption=response["caption"], use_container_width=True)
            else:
                with st.chat_message("assistant"):
                    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ÙÚ©Ø± Ú©Ø±Ø¯Ù†..."):
                        full_response = st.write_stream(self.response_generator(user_input))
                response = {"role": "assistant", "type": "text", "content": full_response}

            st.session_state.chat_history.append(response)


if __name__ == "__main__":
    app = App()
    app.run()
